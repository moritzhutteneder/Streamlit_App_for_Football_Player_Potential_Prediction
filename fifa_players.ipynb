{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib\n",
    "from sklearn import set_config\n",
    "\n",
    "set_config(transform_output='pandas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Path and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c:\\\\Users\\\\morit\\\\OneDrive\\\\Dokumente\\\\ESADE\\\\Term3\\\\AI Prototypes\\\\Assignment 1\\\\European Soccer Database\\\\app.py', 'c:\\\\Users\\\\morit\\\\OneDrive\\\\Dokumente\\\\ESADE\\\\Term3\\\\AI Prototypes\\\\Assignment 1\\\\European Soccer Database\\\\best_model.pkl', 'c:\\\\Users\\\\morit\\\\OneDrive\\\\Dokumente\\\\ESADE\\\\Term3\\\\AI Prototypes\\\\Assignment 1\\\\European Soccer Database\\\\database.db', 'c:\\\\Users\\\\morit\\\\OneDrive\\\\Dokumente\\\\ESADE\\\\Term3\\\\AI Prototypes\\\\Assignment 1\\\\European Soccer Database\\\\database.sqlite', 'c:\\\\Users\\\\morit\\\\OneDrive\\\\Dokumente\\\\ESADE\\\\Term3\\\\AI Prototypes\\\\Assignment 1\\\\European Soccer Database\\\\data_exploration_page.py', 'c:\\\\Users\\\\morit\\\\OneDrive\\\\Dokumente\\\\ESADE\\\\Term3\\\\AI Prototypes\\\\Assignment 1\\\\European Soccer Database\\\\fifa_players.ipynb', 'c:\\\\Users\\\\morit\\\\OneDrive\\\\Dokumente\\\\ESADE\\\\Term3\\\\AI Prototypes\\\\Assignment 1\\\\European Soccer Database\\\\fifa_stats.py', 'c:\\\\Users\\\\morit\\\\OneDrive\\\\Dokumente\\\\ESADE\\\\Term3\\\\AI Prototypes\\\\Assignment 1\\\\European Soccer Database\\\\player_attributes.csv', 'c:\\\\Users\\\\morit\\\\OneDrive\\\\Dokumente\\\\ESADE\\\\Term3\\\\AI Prototypes\\\\Assignment 1\\\\European Soccer Database\\\\prediction_page.py', 'c:\\\\Users\\\\morit\\\\OneDrive\\\\Dokumente\\\\ESADE\\\\Term3\\\\AI Prototypes\\\\Assignment 1\\\\European Soccer Database\\\\test.py', 'c:\\\\Users\\\\morit\\\\OneDrive\\\\Dokumente\\\\ESADE\\\\Term3\\\\AI Prototypes\\\\Assignment 1\\\\European Soccer Database\\\\agents\\\\agent.py', 'c:\\\\Users\\\\morit\\\\OneDrive\\\\Dokumente\\\\ESADE\\\\Term3\\\\AI Prototypes\\\\Assignment 1\\\\European Soccer Database\\\\agents\\\\__pycache__\\\\agent.cpython-312.pyc']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_x</th>\n",
       "      <th>player_fifa_api_id_x</th>\n",
       "      <th>player_api_id</th>\n",
       "      <th>date</th>\n",
       "      <th>overall_rating</th>\n",
       "      <th>potential</th>\n",
       "      <th>preferred_foot</th>\n",
       "      <th>attacking_work_rate</th>\n",
       "      <th>defensive_work_rate</th>\n",
       "      <th>crossing</th>\n",
       "      <th>...</th>\n",
       "      <th>gk_handling</th>\n",
       "      <th>gk_kicking</th>\n",
       "      <th>gk_positioning</th>\n",
       "      <th>gk_reflexes</th>\n",
       "      <th>id_y</th>\n",
       "      <th>player_name</th>\n",
       "      <th>player_fifa_api_id_y</th>\n",
       "      <th>birthday</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>218353</td>\n",
       "      <td>505942</td>\n",
       "      <td>2016-02-18 00:00:00</td>\n",
       "      <td>67.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>right</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>49.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Aaron Appindangoye</td>\n",
       "      <td>218353</td>\n",
       "      <td>1992-02-29 00:00:00</td>\n",
       "      <td>182.88</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>189615</td>\n",
       "      <td>155782</td>\n",
       "      <td>2016-04-21 00:00:00</td>\n",
       "      <td>74.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>left</td>\n",
       "      <td>high</td>\n",
       "      <td>medium</td>\n",
       "      <td>80.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Aaron Cresswell</td>\n",
       "      <td>189615</td>\n",
       "      <td>1989-12-15 00:00:00</td>\n",
       "      <td>170.18</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>186170</td>\n",
       "      <td>162549</td>\n",
       "      <td>2016-01-07 00:00:00</td>\n",
       "      <td>65.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>right</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Aaron Doran</td>\n",
       "      <td>186170</td>\n",
       "      <td>1991-05-13 00:00:00</td>\n",
       "      <td>170.18</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>65</td>\n",
       "      <td>140161</td>\n",
       "      <td>30572</td>\n",
       "      <td>2016-04-21 00:00:00</td>\n",
       "      <td>69.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>right</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>57.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4</td>\n",
       "      <td>Aaron Galindo</td>\n",
       "      <td>140161</td>\n",
       "      <td>1982-05-08 00:00:00</td>\n",
       "      <td>182.88</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>88</td>\n",
       "      <td>17725</td>\n",
       "      <td>23780</td>\n",
       "      <td>2015-12-24 00:00:00</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>right</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5</td>\n",
       "      <td>Aaron Hughes</td>\n",
       "      <td>17725</td>\n",
       "      <td>1979-11-08 00:00:00</td>\n",
       "      <td>182.88</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id_x  player_fifa_api_id_x  player_api_id                 date  \\\n",
       "0      1                218353         505942  2016-02-18 00:00:00   \n",
       "5      6                189615         155782  2016-04-21 00:00:00   \n",
       "38    39                186170         162549  2016-01-07 00:00:00   \n",
       "64    65                140161          30572  2016-04-21 00:00:00   \n",
       "87    88                 17725          23780  2015-12-24 00:00:00   \n",
       "\n",
       "    overall_rating  potential preferred_foot attacking_work_rate  \\\n",
       "0             67.0       71.0          right              medium   \n",
       "5             74.0       76.0           left                high   \n",
       "38            65.0       67.0          right              medium   \n",
       "64            69.0       69.0          right              medium   \n",
       "87            70.0       70.0          right              medium   \n",
       "\n",
       "   defensive_work_rate  crossing  ...  gk_handling  gk_kicking  \\\n",
       "0               medium      49.0  ...         11.0        10.0   \n",
       "5               medium      80.0  ...          7.0         9.0   \n",
       "38              medium      64.0  ...         11.0        12.0   \n",
       "64              medium      57.0  ...         12.0        13.0   \n",
       "87              medium      46.0  ...          6.0        16.0   \n",
       "\n",
       "    gk_positioning  gk_reflexes  id_y         player_name  \\\n",
       "0              8.0          8.0     1  Aaron Appindangoye   \n",
       "5              9.0         12.0     2     Aaron Cresswell   \n",
       "38             9.0         13.0     3         Aaron Doran   \n",
       "64            12.0         11.0     4       Aaron Galindo   \n",
       "87            12.0         11.0     5        Aaron Hughes   \n",
       "\n",
       "    player_fifa_api_id_y             birthday  height  weight  \n",
       "0                 218353  1992-02-29 00:00:00  182.88     187  \n",
       "5                 189615  1989-12-15 00:00:00  170.18     146  \n",
       "38                186170  1991-05-13 00:00:00  170.18     163  \n",
       "64                140161  1982-05-08 00:00:00  182.88     198  \n",
       "87                 17725  1979-11-08 00:00:00  182.88     154  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the current working directory\n",
    "dataset_dir = os.getcwd()\n",
    "\n",
    "# Get the path to the SQLite database file\n",
    "data_paths = [os.path.join(pth, f) for pth, dirs, files in os.walk(dataset_dir) for f in files]\n",
    "database_path = next((path for path in data_paths if path.endswith('.sqlite')), None)\n",
    "print(data_paths)\n",
    "\n",
    "# Check if the database file was found\n",
    "if database_path is None:\n",
    "    raise FileNotFoundError(\"SQLite database file not found in the specified directory\")\n",
    "\n",
    "# Connect to the SQLite database\n",
    "cnx = sqlite3.connect(database_path)\n",
    "\n",
    "# Load the 'Player' table into a pandas DataFrame\n",
    "df_player = pd.read_sql_query(\"SELECT * FROM Player\", cnx)\n",
    "\n",
    "# Load the 'Player_Attributes' table into a pandas DataFrame\n",
    "df_player_attributes = pd.read_sql_query(\"SELECT * FROM Player_Attributes\", cnx)\n",
    "\n",
    "# Close the database connection\n",
    "cnx.close()\n",
    "\n",
    "# Merge the two datasets on 'player_api_id'\n",
    "df_merged = pd.merge(df_player_attributes, df_player, on='player_api_id', how='inner')\n",
    "\n",
    "# Remove duplicates based on 'player_fifa_api_id_x'\n",
    "df_unique = df_merged.drop_duplicates(subset=['player_fifa_api_id_x'])\n",
    "\n",
    "#Remove rows with missing values in the 'potential' column\n",
    "df_unique = df_unique.dropna(subset=['potential'])\n",
    "\n",
    "# Display the first few rows of the unique dataframe\n",
    "df_unique.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for Nan values in potential\n",
    "df_unique['potential'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features and target variable\n",
    "X = df_unique.drop(columns=[\n",
    "    'id_x', 'player_fifa_api_id_x', 'player_api_id', 'date', 'id_y',\n",
    "    'player_name', 'player_fifa_api_id_y', 'potential'\n",
    "])\n",
    "y = df_unique['potential']\n",
    "\n",
    "# Convert 'birthday' to age\n",
    "X['birthday'] = pd.to_datetime(X['birthday'])\n",
    "current_date = pd.Timestamp.now()\n",
    "X['age'] = (current_date - X['birthday']).dt.days / 365.25  # Convert age to years\n",
    "\n",
    "# Drop 'birthday' as we now have 'age'\n",
    "X = X.drop(columns=['birthday'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the training data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define numerical features\n",
    "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# define categorical features\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# preprocess categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value= -1))\n",
    "])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 2.382930454594749\n",
      "Model saved to best_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# Define the model with manually set hyperparameters\n",
    "model = RandomForestRegressor(n_estimators=100, max_features='sqrt', max_depth=30, random_state=42)\n",
    "\n",
    "# Create a pipeline that includes preprocessing and the model\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('model', model)])\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = pipeline.predict(X_val)\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "rmse = mse ** 0.5\n",
    "print(f'Root Mean Squared Error: {rmse}')\n",
    "\n",
    "# Save the model to a file\n",
    "model_filename = 'best_model.pkl'\n",
    "joblib.dump(pipeline, model_filename)\n",
    "print(f'Model saved to {model_filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                feature  importance\n",
      "0        overall_rating    0.231924\n",
      "36          gk_reflexes    0.101199\n",
      "10                curve    0.074809\n",
      "14         acceleration    0.074057\n",
      "6      heading_accuracy    0.049829\n",
      "4              crossing    0.048477\n",
      "27               vision    0.035780\n",
      "26          positioning    0.027646\n",
      "23           long_shots    0.024742\n",
      "12         long_passing    0.020835\n",
      "9             dribbling    0.020742\n",
      "22             strength    0.018761\n",
      "28            penalties    0.018742\n",
      "16              agility    0.017550\n",
      "11   free_kick_accuracy    0.016127\n",
      "2   attacking_work_rate    0.015771\n",
      "24           aggression    0.015426\n",
      "33          gk_handling    0.015026\n",
      "20              jumping    0.015005\n",
      "3   defensive_work_rate    0.014185\n",
      "29              marking    0.013986\n",
      "30      standing_tackle    0.012745\n",
      "32            gk_diving    0.010067\n",
      "1        preferred_foot    0.008673\n",
      "31       sliding_tackle    0.007957\n",
      "18              balance    0.007878\n",
      "39                  age    0.007546\n",
      "21              stamina    0.007393\n",
      "38               weight    0.007036\n",
      "8               volleys    0.006863\n",
      "5             finishing    0.006450\n",
      "17            reactions    0.006433\n",
      "19           shot_power    0.006383\n",
      "13         ball_control    0.006290\n",
      "7         short_passing    0.006194\n",
      "25        interceptions    0.006054\n",
      "15         sprint_speed    0.005503\n",
      "35       gk_positioning    0.005289\n",
      "34           gk_kicking    0.003838\n",
      "37               height    0.000787\n"
     ]
    }
   ],
   "source": [
    "# look at feature importances\n",
    "importances = pipeline.named_steps['model'].feature_importances_\n",
    "features = X_train.columns\n",
    "importances_df = pd.DataFrame({'feature': features, 'importance': importances})\n",
    "importances_df = importances_df.sort_values(by='importance', ascending=False)\n",
    "print(importances_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a list of the top 10 features\n",
    "top_features = importances_df['feature'].head(10).tolist()\n",
    "\n",
    "# Select only top features\n",
    "X_train_filter = X_train[top_features]\n",
    "X_val_filter = X_val[top_features]\n",
    "X_test_filter = X_test[top_features]\n",
    "\n",
    "# Define numerical features\n",
    "numerical_features = X_train_filter.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# define categorical features\n",
    "categorical_features = X_train_filter.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# preprocess categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value= -1))\n",
    "])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 3.39980553561416\n",
      "Model saved to best_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# Define the model with manually set hyperparameters\n",
    "model = RandomForestRegressor(n_estimators=100, max_features='sqrt', max_depth=30, random_state=42)\n",
    "\n",
    "# Create a pipeline that includes preprocessing and the model\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('model', model)])\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train_filter, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = pipeline.predict(X_val_filter)\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "rmse = mse ** 0.5\n",
    "print(f'Root Mean Squared Error: {rmse}')\n",
    "\n",
    "# Save the model to a file\n",
    "model_filename = 'best_model.pkl'\n",
    "joblib.dump(pipeline, model_filename)\n",
    "print(f'Model saved to {model_filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error on Test Set: 3.418481720582516\n"
     ]
    }
   ],
   "source": [
    "# Generalization score\n",
    "y_pred = pipeline.predict(X_test_filter)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mse ** 0.5\n",
    "print(f'Root Mean Squared Error on Test Set: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['num__overall_rating' 'num__gk_reflexes' 'num__curve' 'num__acceleration'\n",
      " 'num__crossing' 'num__heading_accuracy' 'num__vision' 'num__positioning'\n",
      " 'num__long_shots' 'num__dribbling']\n"
     ]
    }
   ],
   "source": [
    "importances = pipeline.named_steps['model'].feature_names_in_\n",
    "print(importances)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Streamlit App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from agents.agent import strenght_weakness_agent, potential_vs_rating\n",
    "\n",
    "# Load the trained model\n",
    "model = joblib.load('best_model.pkl')\n",
    "\n",
    "# Set up page configuration\n",
    "st.set_page_config(page_title=\"Soccer Player Potential Predictor\", page_icon=\"⚽\", layout=\"wide\")\n",
    "\n",
    "# Custom CSS for theming\n",
    "st.markdown(\n",
    "    \"\"\"\n",
    "    <style>\n",
    "    .main {\n",
    "        background-color: #f0f0f0;\n",
    "        font-family: Arial, sans-serif;\n",
    "    }\n",
    "    .sidebar .sidebar-content {\n",
    "        background-color: #004d66;\n",
    "        color: white;\n",
    "    }\n",
    "    .stButton>button {\n",
    "        background-color: #004d66;\n",
    "        color: white;\n",
    "        border-radius: 10px;\n",
    "        border: none;\n",
    "    }\n",
    "    .stButton>button:hover {\n",
    "        background-color: #00334d;\n",
    "        color: white;\n",
    "    }\n",
    "    .stSlider>div>div {\n",
    "        color: #004d66;\n",
    "    }\n",
    "    h1, h2, h3, h4, h5, h6 {\n",
    "        color: #004d66;\n",
    "    }\n",
    "    .block-container {\n",
    "        padding-top: 2rem;\n",
    "    }\n",
    "    </style>\n",
    "    \"\"\",\n",
    "    unsafe_allow_html=True\n",
    ")\n",
    "\n",
    "# Navigation with radio buttons for better visual appeal\n",
    "st.sidebar.title(\"Navigation\")\n",
    "st.sidebar.markdown(\"### Go to:\")\n",
    "page = st.sidebar.radio(\n",
    "    \"\",\n",
    "    [\"Introduction\", \"Data Exploration\", \"Predictions\", \"Feature Importance\"]\n",
    ")\n",
    "\n",
    "# Initialize session state\n",
    "if 'page' not in st.session_state:\n",
    "    st.session_state.page = \"Introduction\"\n",
    "\n",
    "# Set the current page based on user selection\n",
    "st.session_state.page = page\n",
    "\n",
    "# Introduction Page\n",
    "if st.session_state.page == \"Introduction\":\n",
    "    st.title(\"Welcome to the Soccer Player Potential Predictor App\")\n",
    "    st.write(\"\"\"\n",
    "    #### This app is designed to assist football scouts in evaluating and predicting the future potential of soccer players.\n",
    "    By leveraging machine learning models and advanced data analytics, scouts can make informed decisions about player development and recruitment.\n",
    "\n",
    "    **Key Features:**\n",
    "    - **Data Exploration:** Upload player data to explore various attributes and statistics.\n",
    "    - **Potential Prediction:** Predict the future potential of players based on their current attributes.\n",
    "    - **Strengths and Weaknesses Analysis:** Get detailed insights into the strengths and weaknesses of players.\n",
    "    - **Feature Importance:** Understand the importance of different attributes in predicting player potential.\n",
    "\n",
    "    **How to Use:**\n",
    "    - Navigate through different sections using the sidebar.\n",
    "    - Explore player data in the Data Exploration section to visualize and analyze attributes.\n",
    "    - Input player attributes manually in the Predictions section to get potential predictions.\n",
    "    - View the importance of different features in the Feature Importance section.\n",
    "\n",
    "    **Why Use This App?**\n",
    "    This tool provides football scouts with:\n",
    "    - Objective insights into player potential.\n",
    "    - Data-driven analysis for better decision-making.\n",
    "    - Enhanced ability to identify promising talent.\n",
    "\n",
    "\n",
    "    **Get Started:**\n",
    "    Use the sidebar to navigate to the different sections of the app and start exploring player data and predictions.\n",
    "    \"\"\")\n",
    "\n",
    "# Data Exploration Page\n",
    "elif st.session_state.page == \"Data Exploration\":\n",
    "    st.title(\"Data Exploration\")\n",
    "    # File uploader for data exploration\n",
    "    uploaded_file = 'unique_player_data.csv'\n",
    "    if uploaded_file is not None:\n",
    "        df = pd.read_csv(uploaded_file)\n",
    "        \n",
    "        # Sidebar filters\n",
    "        st.sidebar.header(\"Filters\")\n",
    "        numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "        feature = st.sidebar.selectbox(\"Feature to analyze\", numeric_columns)\n",
    "        min_rating = st.sidebar.slider(\"Minimum Potential\", int(df['potential'].min()), int(df['potential'].max()), int(df['potential'].min()))\n",
    "        max_rating = st.sidebar.slider(\"Maximum Potential\", int(df['potential'].min()), int(df['potential'].max()), int(df['potential'].max()))\n",
    "\n",
    "        # Apply filters to the dataframe\n",
    "        filtered_df = df[(df['potential'] >= min_rating) & (df['potential'] <= max_rating)]\n",
    "\n",
    "        # Display filtered data\n",
    "        st.write(f\"Data filtered by Potential between {min_rating} and {max_rating}\")\n",
    "        st.write(filtered_df.head())\n",
    "\n",
    "        # Interactive plots\n",
    "        st.write(f\"Analysis of {feature}\")\n",
    "\n",
    "        # Histogram\n",
    "        st.write(\"Histogram\")\n",
    "        fig = px.histogram(filtered_df, x=feature)\n",
    "        st.plotly_chart(fig)\n",
    "\n",
    "        # Box Plot\n",
    "        st.write(\"Box Plot\")\n",
    "        fig = px.box(filtered_df, y=feature)\n",
    "        st.plotly_chart(fig)\n",
    "\n",
    "        # Scatter Plot\n",
    "        st.write(\"Scatter Plot\")\n",
    "        scatter_x = st.selectbox(\"X-axis\", numeric_columns, index=0)\n",
    "        scatter_y = st.selectbox(\"Y-axis\", numeric_columns, index=1)\n",
    "        fig = px.scatter(filtered_df, x=scatter_x, y=scatter_y)\n",
    "        st.plotly_chart(fig)\n",
    "\n",
    "        # Add a dropdown with Player names\n",
    "        player_names = df['player_name'].unique()\n",
    "        player_name = st.selectbox(\"Select Player\", player_names, index=0)\n",
    "        player_data = df[df['player_name'] == player_name]\n",
    "        st.write(\"Player Data:\")\n",
    "        st.write(player_data)\n",
    "        st.write(strenght_weakness_agent(player_data))\n",
    "\n",
    "# Predictions Page\n",
    "elif st.session_state.page == \"Predictions\":\n",
    "    st.title(\"Predictions\")\n",
    "    st.header(\"Input Player Attributes Manually\")\n",
    "    st.write(\"The generalization score of the model is RSME = 3.42\")\n",
    "\n",
    "    # Input attributes for prediction. Attributes are the top 10 features\n",
    "    importances = model.named_steps['model'].feature_names_in_\n",
    "    attributes = {}\n",
    "    for f in importances:\n",
    "        attributes[f] = st.slider(f, value=50, min_value=0, max_value=100, step=1)\n",
    "    \n",
    "\n",
    "    # Predict button for manual input\n",
    "    if st.button(\"Predict Potential\"):\n",
    "        input_data = pd.DataFrame([attributes])\n",
    "        input_data.columns = [col.split('__')[-1] for col in input_data.columns.to_list()]\n",
    "        prediction = model.predict(input_data)[0]\n",
    "        rounded_prediction = round(prediction)\n",
    "        st.subheader(f\"Predicted Potential: {rounded_prediction}\")\n",
    "        st.write(potential_vs_rating({'overall_rating': input_data['overall_rating'][0], 'potential': rounded_prediction}))\n",
    "\n",
    "\n",
    "# Feature Importance Page\n",
    "elif st.session_state.page == \"Feature Importance\":\n",
    "    st.title(\"Feature Importance\")\n",
    "    # Assuming you have a feature importance array or similar from your model\n",
    "    importances = model.named_steps['model'].feature_importances_\n",
    "    feature_names = model.named_steps['model'].feature_names_in_\n",
    "    feature_importance_df = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
    "    feature_importance_df['feature'] = feature_importance_df['feature'].str.split('__').str[-1]\n",
    "    feature_importance_df = feature_importance_df.sort_values(by='importance', ascending=True) \n",
    "     \n",
    "    # Plot feature importances\n",
    "    st.write(\"Feature Importance Plot\")\n",
    "    fig = px.bar(feature_importance_df, x='importance', y='feature', orientation='h', color='importance', color_continuous_scale='Viridis')\n",
    "    st.plotly_chart(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
